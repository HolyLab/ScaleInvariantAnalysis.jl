var documenterSearchIndex = {"docs":
[{"location":"#ScaleInvariantAnalysis","page":"Home","title":"ScaleInvariantAnalysis","text":"This small package provides a number of tools for numerical analysis under conditions where the underlying problems are scale-invariant. At present it is oriented toward the types of problems that appear in mathematical optimization. Under scaling transformations x rightarrow s odot x (odot is the Hadamard product), a Hessian matrix H transforms as H rightarrow H oslash (s otimes s). Therefore, operations like norm(H) are non-sensical. Nevertheless, we work on computers with finite precision, so operations like Hx and H^-1 g are expected to have some error. This package provides tools for calculating and estimating errors in a scale-covariant manner.","category":"section"},{"location":"#Example","page":"Home","title":"Example","text":"Suppose you have a diagonal Hessian matrix and you estimate its condition number using tools that are not scale-invariant:\n\njulia> using LinearAlgebra\n\njulia> H = [1 0; 0 1e-8];\n\njulia> cond(H)\n1.0e8\n\nYou might declare this matrix to be \"poorly scaled.\" However, the operations H * x and H \\ g both have coordinatewise relative errors of size eps(): there are no delicate cancelations and thus operations involving H reach the full machine precision. This does not seem entirely consistent with common expectations of working with matrices with large condition numbers.\n\nUnder a coordinate transformation x → [x[1], x[2]/10^4], H becomes the identity matrix which has a condition number of 1, and this better reflects our actual experience with operations involving H. This package provides a scale-invariant analog of the condition number:\n\njulia> using ScaleInvariantAnalysis\n\njulia> condscale(H)\n1.0\n\n(You may have some roundoff error in the last few digits.) This version of the condition number matches our actual experience using H. In contrast,\n\njulia> condscale([1 0.9999; 0.9999 1])\n19999.0\n\nremains poorly-conditioned under all scale-transformations of the matrix.","category":"section"},{"location":"#Index-of-available-tools","page":"Home","title":"Index of available tools","text":"","category":"section"},{"location":"#Reference-documentation","page":"Home","title":"Reference documentation","text":"","category":"section"},{"location":"#ScaleInvariantAnalysis.condscale-Tuple{Any}","page":"Home","title":"ScaleInvariantAnalysis.condscale","text":"κ = condscale(A; exact=true)\n\nGiven a symmetric matrix A, return the condition number of the scaled matrix\n\nA ./ (a .* a')\n\nwhere a = symscale(A; exact).\n\nThis is a scale-invariant estimate of the condition number of A.\n\n\n\n\n\n","category":"method"},{"location":"#ScaleInvariantAnalysis.divmag-Tuple{Any, Any}","page":"Home","title":"ScaleInvariantAnalysis.divmag","text":"a, mag = divmag(A, b; cond::Bool=false, kwargs...)\n\nGiven a symmetric matrix A and vector b, for x = A \\ b return a pair where mag is a naive estimate of the magnitude of sum(abs.(x .* a)). a and mag are scale-covariant in circumstances where A \\ b is contravariant. With cond=false, the estimate is based only on the magnitudes of the numbers in A and b, and does not account for the conditioning of A or cancellation in the solution process. Any kwargs are passed to symscale.\n\nThis can be used to form scale-invariant estimates of roundoff errors in computations involving A, b, and x.\n\n\n\n\n\n","category":"method"},{"location":"#ScaleInvariantAnalysis.dotabs-Tuple{AbstractVector{<:Real}, AbstractVector{<:Real}}","page":"Home","title":"ScaleInvariantAnalysis.dotabs","text":"dotabs(x, y)\n\nCompute the sum of absolute values of elementwise products of x and y:\n\n∑_i |x[i] * y[i]|\n\n\n\n\n\n","category":"method"},{"location":"#ScaleInvariantAnalysis.symscale-Tuple{AbstractMatrix}","page":"Home","title":"ScaleInvariantAnalysis.symscale","text":"a = symscale(A; exact=false)\n\nGiven a matrix A assumed to be symmetric, return a vector a representing the \"scale of each axis,\" so that |A[i,j]| ~ a[i] * a[j] for all i, j. a[i] is nonnegative, and is zero only if A[i, j] = 0 for all j.\n\nWith exact=true, a minimizes the objective function\n\n∑_{i,j : A[i,j] ≠ 0} (log(|A[i,j]| / (a[i] * a[j])))²\n\nand is therefore covariant under changes of scale but not general linear transformations.\n\nWith exact=false, the pattern of nonzeros in A is approximated as u * u', where sum(u) * u[i] = nz[i] is the number of nonzero in row i. This results in an O(n^2) rather than O(n^3) algorithm.\n\n\n\n\n\n","category":"method"}]
}
